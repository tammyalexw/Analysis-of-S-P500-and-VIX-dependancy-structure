---
title: "ADL_model_final"
author: "Kellianne Ng"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
#Load Packages 
library(readr)
library(dplyr)
library(lubridate)
library(lmtest)
library(sandwich)
library(tseries)
library(dynlm)
```

# Prepare and clean the data
```{r}
file_path = "../data/sp500_vix_returns.csv"
df = read.csv(file_path)
df = df %>%
  arrange(Date) %>%
  na.omit()

# zoo time series: rsp_t and rvix_t 
z <- zoo(df[, c("rsp", "rvix")], order.by = df$Date)
```

# checking for stationary
```{r}
# ADF test for rsp
adf_rsp = adf.test(df$rsp)
adf_rsp

# ADF test for rvix
adf_rvix = adf.test(df$rvix)
adf_rvix
```

# Implementing the ADL model 
# Yt = S&P500_returns 
# Xt = VIX_returns 

# Determine the optimal lags for p and q 
# p = number of lags for rsp (Y)
# q = number of lags for rvix(X)
```{r}
select_adl_bic <- function(z,
y_name = "rsp",
x_name = "rvix",
p_max = 10,
q_max = 10,
include_x0 = TRUE) {
grid <- expand.grid(p = 0:p_max, q = 0:q_max)
grid$BIC <- NA_real_

best_bic <- Inf
best_fit <- NULL
best_p <- NA_integer_
best_q <- NA_integer_

for (i in seq_len(nrow(grid))) {
p <- grid$p[i]
q <- grid$q[i]

rhs_parts <- c()

# lags of Y: rsp_{t-1}, ..., rsp_{t-p}
if (p > 0) {
  rhs_parts <- c(
    rhs_parts,
    paste0("L(", y_name, ",", 1:p, ")", collapse = " + ")
  )
}

# lags of X: rvix_t, rvix_{t-1}, ..., rvix_{t-q}
if (q > 0) {
  if (include_x0) {
    rhs_parts <- c(
      rhs_parts,
      paste0("L(", x_name, ",", 0:q, ")", collapse = " + ")
    )
  } else {
    rhs_parts <- c(
      rhs_parts,
      paste0("L(", x_name, ",", 1:q, ")", collapse = " + ")
    )
  }
} else if (q == 0 && include_x0) {
  # only contemporaneous X_t
  rhs_parts <- c(rhs_parts, paste0("L(", x_name, ",0)"))
}

# if no regressors, skip (would be just an intercept)
if (length(rhs_parts) == 0) next

fml <- as.formula(
  paste0(y_name, " ~ ", paste(rhs_parts, collapse = " + "))
)

fit <- dynlm::dynlm(fml, data = z)

nobs_fit <- stats::nobs(fit)
k        <- length(coef(fit))
sigma2   <- sum(residuals(fit)^2) / nobs_fit
bic      <- nobs_fit * log(sigma2) + k * log(nobs_fit)

grid$BIC[i] <- bic

if (bic < best_bic) {
  best_bic <- bic
  best_fit <- fit
  best_p   <- p
  best_q   <- q
}
}

list(
best_p = best_p,
best_q = best_q,
best_bic = best_bic,
best_fit = best_fit,
bic_table = grid
)
}

res_adl = select_adl_bic(z,y_name = 'rsp', x_name = 'rvix',p_max = 10, q_max = 10, include_x0 = TRUE)

res_adl$best_p # optimal AR order for rsp
res_adl$best_q # optimal lag order for rvix
res_adl$best_bic # BIC value

head(res_adl$bic_table[order(res_adl$bic_table$BIC), ], 10)
fit_adl = res_adl$best_fit
summary(fit_adl)


```

# Check whether error terms are serially correlated. If they are, it might render the usual homoskedasticity-only 
# and heteroskedasticity- robust standard errors invalid and may cause misleading inference. Hence, we should use
# HAC errors to mitigate this. 
```{r}
res_adl = residuals(fit_adl)

#Breush-Godfrey test 
bgtest(fit_adl, order = 20)

# p = 0.0003221 which is < 0.05, there is evidence of serial correlation 

```

# Given the risk of serial correlation, HAC is required. 
# HAC/ Newey-West robust standard errors
```{r}
hac_lag <- 20

vcov_hac <- NeweyWest(fit_adl, lag = hac_lag, prewhite = FALSE)
coeftest(fit_adl, vcov. = vcov_hac)

```
# Get the R^2
```{r}
s = summary(fit_adl)
s$r.squared
s$adj.r.squared 

```